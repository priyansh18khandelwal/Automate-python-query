name: Run Amazon Scraper Notebook

on:
  schedule:
    - cron: '35 19 * * *'  # Runs daily at 01:05 IST (19:35 UTC)

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the repository
    - name: Checkout code
      uses: actions/checkout@v4

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'  # Specify your preferred Python version

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install papermill jupyter requests beautifulsoup4 pandas  # Add other dependencies as needed

    # Step 4: Run the Jupyter notebook
    - name: Run Amazon Scraper Notebook
      run: |
        papermill amazon_scrap.ipynb output.ipynb -k python3

    # Step 5: (Optional) Commit or save output if needed
    - name: Commit output notebook
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add output.ipynb
        git commit -m "Add output from daily scraper run" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
